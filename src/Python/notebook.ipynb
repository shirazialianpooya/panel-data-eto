{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:168: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df = df.groupby(station_col).apply(fill_short).reset_index(drop=True)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:168: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(station_col).apply(fill_short).reset_index(drop=True)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:172: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  med = df.groupby(station_col)[v].transform(\"median\")\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:219: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:221: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:224: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:225: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
      "INFO:panel_forecast:Within-station metrics: {'rmse': 1.1621422466771822, 'mae': 0.8054505097209308, 'r2': 0.9892473035832806}\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\model.py:1260: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:590: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_mu = self._frame.groupby(level=level).transform(\"mean\")\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:590: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_mu = self._frame.groupby(level=level).transform(\"mean\")\n",
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_15880\\1703540536.py:363: AbsorbingEffectWarning: \n",
      "Variables have been fully absorbed and have removed from the regression:\n",
      "\n",
      "wind_roll_mean_7, lat, lon, elevation, rh_roll_mean_3, rh_roll_mean_7, t_mean_roll_mean_3, t_mean_roll_mean_7, t_max_roll_mean_3, t_max_roll_mean_7, t_min_roll_mean_3, t_min_roll_mean_7, precip_roll_mean_3, precip_roll_mean_7, wind_roll_mean_3\n",
      "\n",
      "  fit = mod.fit(cov_type='clustered', cluster_entity=True)\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:680: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mu = self._frame.groupby(level=level).mean()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:680: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mu = self._frame.groupby(level=level).mean()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:640: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = self._frame.groupby(level=level).count()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:680: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mu = self._frame.groupby(level=level).mean()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:590: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_mu = self._frame.groupby(level=level).transform(\"mean\")\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:680: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mu = self._frame.groupby(level=level).mean()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:680: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mu = self._frame.groupby(level=level).mean()\n",
      "c:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\linearmodels\\panel\\data.py:590: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_mu = self._frame.groupby(level=level).transform(\"mean\")\n",
      "INFO:panel_forecast:Stacked metrics: {'rmse': 1.1607220307422013, 'mae': 0.8024942259575905, 'r2': 0.989273568560141}\n",
      "INFO:panel_forecast:Saved plot plots/obs_pred_S00.png\n",
      "INFO:panel_forecast:Saved to demo_output/within_models.joblib\n",
      "INFO:panel_forecast:Saved to demo_output/scaler.joblib\n",
      "INFO:panel_forecast:Demo complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalIndex(['S00', 'S00', 'S00', 'S00', 'S00', 'S00', 'S00', 'S00',\n",
      "                  'S00', 'S00',\n",
      "                  ...\n",
      "                  'S05', 'S05', 'S05', 'S05', 'S05', 'S05', 'S05', 'S05',\n",
      "                  'S05', 'S05'],\n",
      "                 categories=['S00', 'S01', 'S02', 'S03', 'S04', 'S05'], ordered=False, dtype='category', name='station_id', length=4386)\n"
     ]
    }
   ],
   "source": [
    "# PANEL FORECASTING PACKAGE\n",
    "# Files in this single textdoc shown as separate sections. Save each section into its own .py file as named.\n",
    "\n",
    "# ------------------------- requirements.txt -------------------------\n",
    "# requirements.txt\n",
    "# ---------------------------------------------------------------\n",
    "# pandas>=1.3\n",
    "# numpy>=1.21\n",
    "# scikit-learn>=1.0\n",
    "# matplotlib>=3.4\n",
    "# seaborn>=0.11\n",
    "# joblib>=1.0\n",
    "# xarray>=0.18\n",
    "# linearmodels>=4.24\n",
    "# libpysal>=4.6  # optional (pysal spatial tools)\n",
    "\n",
    "# ------------------------- README.md -------------------------------\n",
    "# README.md\n",
    "# ---------------------------------------------------------------\n",
    "# Panel Forecasting Pipeline\n",
    "# --------------------------\n",
    "# This package implements a modular, end-to-end pipeline for panel-data\n",
    "# forecasting of meteorological variables measured at multiple synoptic stations.\n",
    "# Files:\n",
    "#  - data_processing.py\n",
    "#  - spatial_utils.py\n",
    "#  - models.py\n",
    "#  - train_eval.py\n",
    "#  - utils.py\n",
    "#  - demo.py\n",
    "# Usage:\n",
    "#  1. Save each section of this textdoc to the filename shown in the header.\n",
    "#  2. install requirements: `pip install -r requirements.txt` (optional packages are fine to skip)\n",
    "#  3. Run: `python demo.py` to execute a demo on synthetic data.\n",
    "\n",
    "\n",
    "# ------------------------- utils.py --------------------------------\n",
    "# utils.py\n",
    "# ---------------------------------------------------------------\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import joblib\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"panel_forecast\")\n",
    "\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_pickle(obj: Any, path: str) -> None:\n",
    "    ensure_dir(os.path.dirname(path) or \".\")\n",
    "    joblib.dump(obj, path)\n",
    "    logger.info(f\"Saved to {path}\")\n",
    "\n",
    "\n",
    "def load_pickle(path: str) -> Any:\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "def save_json(obj: Any, path: str) -> None:\n",
    "    ensure_dir(os.path.dirname(path) or \".\")\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    logger.info(f\"Saved JSON to {path}\")\n",
    "\n",
    "\n",
    "# --------------------- spatial_utils.py -----------------------------\n",
    "# spatial_utils.py\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "\n",
    "def haversine(lon1: float, lat1: float, lon2: float, lat2: float) -> float:\n",
    "    \"\"\"Return haversine distance in kilometers.\"\"\"\n",
    "    # convert to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, (lon1, lat1, lon2, lat2))\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6371.0 * c\n",
    "    return km\n",
    "\n",
    "\n",
    "def pairwise_distance_matrix(stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute pairwise haversine distance matrix from stations dataframe with lon/lat columns.\"\"\"\n",
    "    coords = stations[[\"lon\", \"lat\"]].to_numpy()\n",
    "    n = coords.shape[0]\n",
    "    D = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        lon1, lat1 = coords[i]\n",
    "        for j in range(n):\n",
    "            lon2, lat2 = coords[j]\n",
    "            D[i, j] = haversine(lon1, lat1, lon2, lat2)\n",
    "    return pd.DataFrame(D, index=stations.index, columns=stations.index)\n",
    "\n",
    "\n",
    "def inverse_distance_weights(D: pd.DataFrame, max_distance: Optional[float] = None, k_nearest: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Create inverse-distance row-normalized weight matrix. Optionally threshold by max_distance or keep k nearest neighbors.\"\"\"\n",
    "    W = D.copy()\n",
    "    with np.errstate(divide='ignore'):\n",
    "        W = 1.0 / W\n",
    "    np.fill_diagonal(W.values, 0.0)\n",
    "    if max_distance is not None:\n",
    "        W = W.where(D <= max_distance, 0.0)\n",
    "    if k_nearest is not None:\n",
    "        for i in W.index:\n",
    "            row = W.loc[i].copy()\n",
    "            # keep top k\n",
    "            keep = row.nlargest(k_nearest).index\n",
    "            mask = ~row.index.isin(keep)\n",
    "            row[mask] = 0.0\n",
    "            W.loc[i] = row\n",
    "    # row normalization\n",
    "    row_sums = W.sum(axis=1)\n",
    "    row_sums[row_sums == 0] = 1.0\n",
    "    W = W.div(row_sums, axis=0)\n",
    "    return W\n",
    "\n",
    "\n",
    "def spatial_lag(df_values: pd.DataFrame, W: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Given df_values indexed by station_id and columns as times (or vice-versa), compute W * values per time column.\n",
    "    df_values: DataFrame with index=station_id and columns=time or variable.\n",
    "    Returns DataFrame same shape.\"\"\"\n",
    "    # Ensure ordering\n",
    "    W = W.reindex(index=df_values.index, columns=df_values.index).fillna(0.0)\n",
    "    return W.values.dot(df_values.values)\n",
    "\n",
    "\n",
    "# --------------------- data_processing.py ---------------------------\n",
    "# data_processing.py\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "\n",
    "def preprocess_base(df: pd.DataFrame, date_col: str = \"date\", station_col: str = \"station_id\") -> pd.DataFrame:\n",
    "    \"\"\"Parse dates, sort by station and date, and ensure station is category.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([station_col, date_col]).reset_index(drop=True)\n",
    "    df[station_col] = df[station_col].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_stationwise(df: pd.DataFrame, vars_: List[str], station_col: str = \"station_id\", method: str = \"forward_back\", max_gap: int = 3, knn_neighbors: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Impute missing values: short gaps per-station forward/backward fill up to max_gap; then KNN across stations for remaining gaps.\n",
    "    Returns imputed df.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # forward/backward fill per station\n",
    "    def fill_short(group):\n",
    "        for v in vars_:\n",
    "            # limit the forward/back to max_gap by using group-specific mask\n",
    "            group[v] = group[v].ffill(limit=max_gap).bfill(limit=max_gap)\n",
    "        return group\n",
    "\n",
    "    df = df.groupby(station_col).apply(fill_short).reset_index(drop=True)\n",
    "\n",
    "    # remaining missing -> per-station median\n",
    "    for v in vars_:\n",
    "        med = df.groupby(station_col)[v].transform(\"median\")\n",
    "        df[v] = df[v].fillna(med)\n",
    "\n",
    "    # if still missing, use KNN across station/time stacked features\n",
    "    remaining = df[vars_].isna().any().any()\n",
    "    if remaining:\n",
    "        logger.info(\"Falling back to KNN imputer across all rows\")\n",
    "        imputer = KNNImputer(n_neighbors=knn_neighbors)\n",
    "        df[vars_] = imputer.fit_transform(df[vars_])\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_impossible_values(df: pd.DataFrame, rules: Dict[str, Tuple[Optional[float], Optional[float]]]) -> pd.DataFrame:\n",
    "    \"\"\"Clip or set to NaN values outside allowed ranges. rules: var -> (min, max) where None means no bound.\"\"\"\n",
    "    df = df.copy()\n",
    "    for var, (minv, maxv) in rules.items():\n",
    "        if var in df.columns:\n",
    "            if minv is not None:\n",
    "                df.loc[df[var] < minv, var] = np.nan\n",
    "            if maxv is not None:\n",
    "                df.loc[df[var] > maxv, var] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_time_features(df: pd.DataFrame, date_col: str = \"date\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dt = df[date_col]\n",
    "    df[\"doy\"] = dt.dt.dayofyear\n",
    "    df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "    df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "    df[\"month\"] = dt.dt.month.astype(\"category\")\n",
    "    df[\"weekday\"] = dt.dt.weekday.astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_lag_rolling(df: pd.DataFrame, vars_: List[str], lags: List[int] = None, seasonal_lag: int = 365, windows: List[int] = None, station_col: str = \"station_id\", date_col: str = \"date\") -> pd.DataFrame:\n",
    "    \"\"\"Create lag and rolling features per station.\n",
    "    lags: list of lags to create (e.g., [1..7]). windows: list of rolling windows.\n",
    "    \"\"\"\n",
    "    if lags is None:\n",
    "        lags = list(range(1, 8))\n",
    "    if windows is None:\n",
    "        windows = [3, 7, 30]\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([station_col, date_col])\n",
    "    for var in vars_:\n",
    "        for lag in lags:\n",
    "            df[f\"{var}_lag_{lag}\"] = df.groupby(station_col)[var].shift(lag)\n",
    "        # seasonal lag\n",
    "        df[f\"{var}_lag_seasonal_{seasonal_lag}\"] = df.groupby(station_col)[var].shift(seasonal_lag)\n",
    "        # rolling\n",
    "        for w in windows:\n",
    "            df[f\"{var}_roll_mean_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
    "            df[f\"{var}_roll_std_{w}\"] = df.groupby(station_col)[var].transform(lambda x: x.shift(1).rolling(w, min_periods=1).std())\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_feature_matrix(df: pd.DataFrame, target: str, feature_cols: Optional[List[str]] = None, station_col: str = \"station_id\", date_col: str = \"date\") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Return X, y aligned and drop rows with NaN in target.\"\"\"\n",
    "    df = df.copy()\n",
    "    if feature_cols is None:\n",
    "        # use all columns except date, station, and target\n",
    "        exclude = {station_col, date_col, target}\n",
    "        feature_cols = [c for c in df.columns if c not in exclude]\n",
    "    X = df[[station_col, date_col] + feature_cols].copy()\n",
    "    y = df[[station_col, date_col, target]].copy()\n",
    "    # drop rows where target is NaN\n",
    "    mask = y[target].notna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    # set index multiindex for convenience\n",
    "    X = X.set_index([station_col, date_col])\n",
    "    y = y.set_index([station_col, date_col])[target]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fit_scalers(X: pd.DataFrame, scaler: Optional[StandardScaler] = None) -> Tuple[StandardScaler, pd.DataFrame]:\n",
    "    \"\"\"Fit a StandardScaler across rows on numeric columns and return scaled DataFrame and scaler.\"\"\"\n",
    "    num = X.select_dtypes(include=[\"number\"]).copy()\n",
    "    scaler = scaler or StandardScaler()\n",
    "    scaled = scaler.fit_transform(num)\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[num.columns] = scaled\n",
    "    return scaler, X_scaled\n",
    "\n",
    "\n",
    "def to_tensor(df: pd.DataFrame, vars_: List[str], station_col: str = \"station_id\", date_col: str = \"date\"):\n",
    "    \"\"\"Return numpy tensor (n_stations, n_vars, n_times) and time index and station list.\"\"\"\n",
    "    df = df.copy()\n",
    "    stations = df[station_col].cat.categories if pd.api.types.is_categorical_dtype(df[station_col]) else df[station_col].unique()\n",
    "    times = pd.Index(sorted(df[date_col].unique()))\n",
    "    n_s = len(stations)\n",
    "    n_t = len(times)\n",
    "    n_v = len(vars_)\n",
    "    tensor = np.full((n_s, n_v, n_t), np.nan, dtype=float)\n",
    "    s_to_idx = {s: i for i, s in enumerate(stations)}\n",
    "    t_to_idx = {t: i for i, t in enumerate(times)}\n",
    "    for _, row in df.iterrows():\n",
    "        s = row[station_col]\n",
    "        t = row[date_col]\n",
    "        if s in s_to_idx and t in t_to_idx:\n",
    "            i = s_to_idx[s]\n",
    "            j = t_to_idx[t]\n",
    "            tensor[i, :, j] = [row.get(v, np.nan) for v in vars_]\n",
    "    return tensor, list(stations), times\n",
    "\n",
    "\n",
    "# --------------------- models.py ------------------------------------\n",
    "# models.py\n",
    "# ---------------------------------------------------------------\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from sklearn.linear_model import ElasticNetCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "try:\n",
    "    from linearmodels.panel import PanelOLS\n",
    "    from linearmodels.panel import RandomEffects\n",
    "    HAVE_LINEARMODELS = True\n",
    "except Exception:\n",
    "    HAVE_LINEARMODELS = False\n",
    "\n",
    "\n",
    "def train_within_station_models(X: pd.DataFrame, y: pd.Series, model_type: str = \"rf\", per_station: bool = True, random_state: int = 42, **kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"Train per-station models. Returns dict station_id -> trained model.\"\"\"\n",
    "    models = {}\n",
    "    stations = X.index.get_level_values(0).unique()\n",
    "    for s in stations:\n",
    "        Xs = X.xs(s)\n",
    "        ys = y.xs(s)\n",
    "        # drop rows with NaN\n",
    "        mask = Xs.notna().all(axis=1) & ys.notna()\n",
    "        Xs = Xs.loc[mask]\n",
    "        ys = ys.loc[mask]\n",
    "        if Xs.shape[0] < 10:\n",
    "            logger.warning(f\"Station {s} has too few rows ({Xs.shape[0]}), skipping\")\n",
    "            continue\n",
    "        if model_type == \"enet\":\n",
    "            m = ElasticNetCV(cv=5, random_state=random_state)\n",
    "        elif model_type == \"rf\":\n",
    "            m = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "        else:\n",
    "            m = GradientBoostingRegressor(random_state=random_state)\n",
    "        m.fit(Xs, ys)\n",
    "        models[str(s)] = m\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_within(models: Dict[str, Any], X: pd.DataFrame) -> pd.Series:\n",
    "    out = []\n",
    "    for (s, date), _ in X.iterrows():\n",
    "        Xrow = X.loc[(s, date)].to_frame().T\n",
    "        model = models.get(str(s))\n",
    "        if model is None:\n",
    "            out.append(np.nan)\n",
    "        else:\n",
    "            out.append(float(model.predict(Xrow)[0]))\n",
    "    return pd.Series(out, index=X.index)\n",
    "\n",
    "\n",
    "def fit_panel_models(X: pd.DataFrame, y: pd.Series, entity_effects: bool = True, time_effects: bool = False) -> Dict[str, Any]:\n",
    "    \"\"\"Fit panel FE and RE models using linearmodels if available. Returns dict of results.\"\"\"\n",
    "    res = {}\n",
    "    if not HAVE_LINEARMODELS:\n",
    "        logger.warning(\"linearmodels not installed; falling back to OLS with dummies\")\n",
    "        # fallback: create dummies for station and optionally date\n",
    "        df = X.reset_index()\n",
    "        df[\"_y\"] = y.reset_index(drop=True)\n",
    "        station_dummies = pd.get_dummies(df[\"station_id\"], drop_first=True)\n",
    "        Xd = pd.concat([df.drop(columns=[\"station_id\", \"date\"]), station_dummies], axis=1)\n",
    "        import statsmodels.api as sm\n",
    "        mdl = sm.OLS(df[\"_y\"], sm.add_constant(Xd)).fit()\n",
    "        res[\"ols_with_dummies\"] = mdl\n",
    "        return res\n",
    "\n",
    "    # prepare panel DataFrame\n",
    "    df = X.reset_index()\n",
    "    df[\"y\"] = y.reset_index(drop=True)\n",
    "    df = df.set_index([\"station_id\", \"date\"]).sort_index()\n",
    "    # drop non-numeric columns\n",
    "    exog = df.select_dtypes(include=[\"number\"]).drop(columns=[\"y\"], errors='ignore')\n",
    "    if exog.shape[1] == 0:\n",
    "        raise ValueError(\"No numeric regressors available for panel model\")\n",
    "    import statsmodels.api as sm\n",
    "    exog = sm.add_constant(exog)\n",
    "    if entity_effects:\n",
    "        mod = PanelOLS(df[\"y\"], exog, entity_effects=True, time_effects=time_effects, check_rank=False, drop_absorbed=True)\n",
    "    else:\n",
    "        mod = RandomEffects(df[\"y\"], exog)\n",
    "    fit = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "    res[\"fit\"] = fit\n",
    "    return res\n",
    "\n",
    "\n",
    "def spatial_hybrid_features(df: pd.DataFrame, W: pd.DataFrame, vars_: List[str], station_col: str = \"station_id\", date_col: str = \"date\") -> pd.DataFrame:\n",
    "    \"\"\"Add spatial lag features W * var_t and W * var_{t-1} into dataframe.\n",
    "    Assumes df indexed by station,date or columns exist.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # pivot so rows=station, cols=time\n",
    "    for var in vars_:\n",
    "        pv = df.pivot(index=station_col, columns=date_col, values=var)\n",
    "        lag0 = pd.DataFrame(spatial_lag(pv, W), index=pv.index, columns=pv.columns)\n",
    "        lag1 = pd.DataFrame(spatial_lag(pv.shift(1, axis=1), W), index=pv.index, columns=pv.columns)\n",
    "        # melt back\n",
    "        m0 = lag0.stack().rename(f\"{var}_spat_lag0\")\n",
    "        m1 = lag1.stack().rename(f\"{var}_spat_lag1\")\n",
    "        df = df.join(m0, on=[station_col, date_col])\n",
    "        df = df.join(m1, on=[station_col, date_col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def stacking_meta_learner(predictions: pd.DataFrame, y: pd.Series, \n",
    "                          meta_model=None):\n",
    "    \"\"\"Train a meta-learner on base model predictions.\"\"\"\n",
    "    if meta_model is None:\n",
    "        from sklearn.linear_model import RidgeCV\n",
    "        meta_model = RidgeCV(alphas=np.logspace(-3, 3, 7))\n",
    "    \n",
    "    # Handle NaN predictions (e.g., if some base models missing output)\n",
    "    X = predictions.fillna(0)   # simple choice, or use predictions.mean()\n",
    "    mask = y.notna() & X.notna().all(axis=1)\n",
    "    \n",
    "    meta_model.fit(X.loc[mask], y.loc[mask])\n",
    "    return meta_model\n",
    "\n",
    "\n",
    "# --------------------- train_eval.py -------------------------------\n",
    "# train_eval.py\n",
    "# ---------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def rolling_origin_splits(df: pd.DataFrame, n_splits: int = 3, initial_window: int = 365, step: int = 90, date_col: str = \"date\", station_col: str = \"station_id\"):\n",
    "    \"\"\"Yield train/val index masks for time-aware CV. This simple implementation uses global time index.\"\"\"\n",
    "    times = pd.Index(sorted(df[date_col].unique()))\n",
    "    starts = [times[0] + pd.Timedelta(days=int(step * i)) for i in range(n_splits)]\n",
    "    for i in range(n_splits):\n",
    "        start = starts[i]\n",
    "        train_end = start + pd.Timedelta(days=initial_window)\n",
    "        val_end = train_end + pd.Timedelta(days=step)\n",
    "        train_mask = df[date_col] <= train_end\n",
    "        val_mask = (df[date_col] > train_end) & (df[date_col] <= val_end)\n",
    "        yield train_mask, val_mask\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true: pd.Series, y_pred: pd.Series) -> Dict[str, float]:\n",
    "    mask = y_true.notna() & y_pred.notna()\n",
    "    if mask.sum() == 0:\n",
    "        return {\"rmse\": np.nan, \"mae\": np.nan, \"r2\": np.nan}\n",
    "    y_true = y_true.loc[mask]\n",
    "    y_pred = y_pred.loc[mask]\n",
    "    return {\n",
    "        \"rmse\": float(np.sqrt(mean_squared_error(y_true, y_pred))),\n",
    "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"r2\": float(r2_score(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_obs_vs_pred(y_true: pd.Series, y_pred: pd.Series, station: str, out_path: str = \"plots\"):\n",
    "    ensure_dir(out_path)\n",
    "    df = pd.concat([y_true.rename('obs'), y_pred.rename('pred')], axis=1)\n",
    "    df = df.sort_index(level=1)  # sort by date\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df.index.get_level_values(1), df['obs'], label='obs')\n",
    "    plt.plot(df.index.get_level_values(1), df['pred'], label='pred')\n",
    "    plt.title(f\"Observed vs Predicted - {station}\")\n",
    "    plt.legend()\n",
    "    p = f\"{out_path}/obs_pred_{station}.png\"\n",
    "    plt.savefig(p, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved plot {p}\")\n",
    "\n",
    "\n",
    "def plot_residuals_acf(resid: pd.Series, station: str, lags: int = 30, out_path: str = \"plots\"):\n",
    "    ensure_dir(out_path)\n",
    "    from statsmodels.graphics.tsaplots import plot_acf\n",
    "    plt.figure()\n",
    "    plot_acf(resid.dropna(), lags=lags)\n",
    "    p = f\"{out_path}/resid_acf_{station}.png\"\n",
    "    plt.savefig(p, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved plot {p}\")\n",
    "\n",
    "\n",
    "def residuals_spatial_heatmap(residuals: pd.Series, stations_meta: pd.DataFrame, out_path: str = \"plots\"):\n",
    "    \"\"\"Create heatmap of pairwise correlations of residuals across stations.\"\"\"\n",
    "    ensure_dir(out_path)\n",
    "    # residuals index: station,date\n",
    "    pivot = residuals.reset_index().pivot(index='date', columns='station_id', values=0)\n",
    "    corr = pivot.corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr, annot=False)\n",
    "    p = f\"{out_path}/resid_spatial_corr.png\"\n",
    "    plt.title(\"Residual correlation across stations\")\n",
    "    plt.savefig(p, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved plot {p}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_station_predictions(y_true: pd.Series, y_pred: pd.Series, station_ids: pd.Series,\n",
    "                             outdir=\"plots/stations\", max_stations=5):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    df = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred, \"station\": station_ids})\n",
    "    \n",
    "    for i, (st, grp) in enumerate(df.groupby(\"station\")):\n",
    "        if i >= max_stations:  #  n       \n",
    "            break\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(grp.index, grp[\"y_true\"], label=\"Observed\", lw=2)\n",
    "        plt.plot(grp.index, grp[\"y_pred\"], label=\"Predicted\", lw=2)\n",
    "        plt.title(f\"Station {st} - Observed vs Predicted\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Target\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"{st}_timeseries.png\"))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def plot_station_scatter(y_true: pd.Series, y_pred: pd.Series, station_ids: pd.Series,\n",
    "                         outdir=\"plots/scatter\", max_stations=5):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    df = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred, \"station\": station_ids})\n",
    "    \n",
    "    for i, (st, grp) in enumerate(df.groupby(\"station\")):\n",
    "        if i >= max_stations:\n",
    "            break\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(grp[\"y_true\"], grp[\"y_pred\"], alpha=0.6)\n",
    "        lims = [min(grp[\"y_true\"].min(), grp[\"y_pred\"].min()),\n",
    "                max(grp[\"y_true\"].max(), grp[\"y_pred\"].max())]\n",
    "        plt.plot(lims, lims, 'r--')  #  1:1\n",
    "        plt.title(f\"Station {st} - Pred vs Obs\")\n",
    "        plt.xlabel(\"Observed\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"{st}_scatter.png\"))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_by_station(y_true: pd.Series, y_pred: pd.Series, station_ids: pd.Series):\n",
    "    results = []\n",
    "    df = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred, \"station\": station_ids})\n",
    "    \n",
    "    for st, grp in df.groupby(\"station\"):\n",
    "        r2 = r2_score(grp[\"y_true\"], grp[\"y_pred\"])\n",
    "        rmse = np.sqrt(mean_squared_error(grp[\"y_true\"], grp[\"y_pred\"]))\n",
    "        mae = mean_absolute_error(grp[\"y_true\"], grp[\"y_pred\"])\n",
    "        results.append({\"station\": st, \"R2\": r2, \"RMSE\": rmse, \"MAE\": mae})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --------------------- demo.py -------------------------------------\n",
    "# demo.py\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# We'll import functions from above as if they were real modules\n",
    "# In practice, save each chunk to separate files and use `from data_processing import ...`\n",
    "\n",
    "\n",
    "def synthetic_data_generator(n_stations: int = 10, years: int = 3, seed: int = 42, missing_frac: float = 0.02) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic daily meteorological panel data with seasonal cycles and spatially correlated noise.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    start = datetime(2018, 1, 1)\n",
    "    end = start + timedelta(days=365 * years)\n",
    "    dates = pd.date_range(start, end, freq='D')\n",
    "    station_ids = [f\"S{i:02d}\" for i in range(n_stations)]\n",
    "    # random station metadata\n",
    "    lats = rng.uniform(-60, 60, size=n_stations)\n",
    "    lons = rng.uniform(-180, 180, size=n_stations)\n",
    "    elev = rng.uniform(0, 3000, size=n_stations)\n",
    "    rows = []\n",
    "    for si, s in enumerate(station_ids):\n",
    "        lat = lats[si]\n",
    "        lon = lons[si]\n",
    "        amp = 10 + (abs(lat) / 90) * 10  # lat-dependent amplitude\n",
    "        phase = rng.uniform(0, 2 * np.pi)\n",
    "        for d in dates:\n",
    "            doy = d.timetuple().tm_yday\n",
    "            seasonal = amp * np.sin(2 * np.pi * doy / 365.25 + phase)\n",
    "            base_temp = 15 + seasonal - elev[si] * 0.0065\n",
    "            t_mean = base_temp + rng.normal(scale=3.0)\n",
    "            t_max = t_mean + abs(rng.normal(scale=2.0))\n",
    "            t_min = t_mean - abs(rng.normal(scale=2.0))\n",
    "            precip = np.abs(rng.exponential(scale=1.0) * (0.3 + 0.7 * rng.binomial(1, 0.1)))\n",
    "            wind = np.abs(rng.normal(3, 1.5))\n",
    "            rh = np.clip(50 + 20 * np.sin(2 * np.pi * doy / 365.25 + phase / 2) + rng.normal(0, 10), 0, 100)\n",
    "            rows.append({\n",
    "                'date': d,\n",
    "                'station_id': s,\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'elevation': elev[si],\n",
    "                't_mean': t_mean,\n",
    "                't_max': t_max,\n",
    "                't_min': t_min,\n",
    "                'precip': precip,\n",
    "                'wind': wind,\n",
    "                'rh': rh\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # introduce missingness\n",
    "    mask = rng.rand(len(df)) < missing_frac\n",
    "    df.loc[mask, 't_max'] = np.nan\n",
    "    df['station_id'] = df['station_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "# config\n",
    "cfg = {\n",
    "    'target': 't_max',\n",
    "    'vars': ['t_mean', 't_min', 'precip', 'wind', 'rh'],\n",
    "    'lags': list(range(1, 8)),\n",
    "    'windows': [3, 7, 30],\n",
    "    'seasonal_lag': 365,\n",
    "    'horizon': 1,\n",
    "    'out_dir': 'demo_output'\n",
    "}\n",
    "\n",
    "df = synthetic_data_generator(n_stations=6, years=2, missing_frac=0.02)\n",
    "# from data_processing import preprocess_base, remove_impossible_values, make_time_features, make_lag_rolling, impute_stationwise, create_feature_matrix, fit_scalers, to_tensor\n",
    "# from spatial_utils import pairwise_distance_matrix, inverse_distance_weights\n",
    "# from models import train_within_station_models, predict_within, fit_panel_models, spatial_hybrid_features, stacking_meta_learner\n",
    "# from train_eval import evaluate_predictions, plot_obs_vs_pred\n",
    "# preprocess\n",
    "df = preprocess_base(df)\n",
    "df = remove_impossible_values(df, rules={'precip': (0.0, None)})\n",
    "df = impute_stationwise(df, vars_=['t_mean', 't_max', 't_min', 'precip', 'wind', 'rh'])\n",
    "df = make_time_features(df)\n",
    "df = make_lag_rolling(df, vars_=cfg['vars'] + [cfg['target']], lags=cfg['lags'], seasonal_lag=cfg['seasonal_lag'], windows=cfg['windows'])\n",
    "# feature matrix\n",
    "X, y = create_feature_matrix(df, target=cfg['target'])\n",
    "scaler, Xs = fit_scalers(X)\n",
    "# spatial\n",
    "stations_meta = df.drop_duplicates('station_id').set_index('station_id')[[ 'lon', 'lat', 'elevation' ]]\n",
    "D = pairwise_distance_matrix(stations_meta.reset_index().rename(columns={'index':'station_id'}).set_index('station_id'))\n",
    "W = inverse_distance_weights(D, k_nearest=3)\n",
    "\n",
    "# add spatial hybrid features\n",
    "df_spat = spatial_hybrid_features(df, W, vars_=['t_mean', 't_min', 'precip'])\n",
    "Xs_spat, y_spat = create_feature_matrix(df_spat, target=cfg['target'])\n",
    "\n",
    "# train within-station models\n",
    "within_models = train_within_station_models(Xs, y, model_type='rf')\n",
    "y_pred_within = predict_within(within_models, Xs)\n",
    "metrics_within = evaluate_predictions(y, y_pred_within)\n",
    "logger.info(f\"Within-station metrics: {metrics_within}\")\n",
    "\n",
    "# panel model\n",
    "panel_res = fit_panel_models(Xs, y, entity_effects=True)\n",
    "\n",
    "if 'fit' in panel_res:\n",
    "    panel_pred = panel_res['fit'].predict()\n",
    "    if isinstance(panel_pred, pd.DataFrame) and panel_pred.shape[1] == 1:\n",
    "        panel_pred = panel_pred.iloc[:, 0]  # flatten to Series\n",
    "else:\n",
    "    panel_pred = pd.Series(np.nan, index=y.index)\n",
    "\n",
    "# stacking\n",
    "preds_df = pd.DataFrame({'within': y_pred_within, 'panel': panel_pred})\n",
    "meta = stacking_meta_learner(preds_df, y)\n",
    "y_meta = pd.Series(meta.predict(preds_df.fillna(0)), index=preds_df.index)\n",
    "metrics_meta = evaluate_predictions(y, y_meta)\n",
    "logger.info(f\"Stacked metrics: {metrics_meta}\")\n",
    "\n",
    "\n",
    "\n",
    "# plots for a sample station\n",
    "sample_station = Xs.index.get_level_values(0).unique()[0]\n",
    "sample_idx = Xs.index[Xs.index.get_level_values(0) == sample_station]\n",
    "plot_obs_vs_pred(y.loc[sample_idx], y_meta.loc[sample_idx], station=str(sample_station))\n",
    "# save\n",
    "ensure_dir(cfg['out_dir'])\n",
    "save_pickle(within_models, f\"{cfg['out_dir']}/within_models.joblib\")\n",
    "save_pickle(scaler, f\"{cfg['out_dir']}/scaler.joblib\")\n",
    "logger.info(\"Demo complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2073da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panel_forecast:Station S00 metrics: {'within': {'rmse': 1.0801473622815871, 'mae': 0.7403780259153616, 'r2': 0.9845056868008393}, 'stacked': {'rmse': 1.0824208774646247, 'mae': 0.7416228717047224, 'r2': 0.9844403926931815}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S00.png\n",
      "INFO:panel_forecast:Station S01 metrics: {'within': {'rmse': 1.1792221090842063, 'mae': 0.8105770426985969, 'r2': 0.9898354770492443}, 'stacked': {'rmse': 1.1790499303377147, 'mae': 0.8070071695391753, 'r2': 0.9898384450856123}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S01.png\n",
      "INFO:panel_forecast:Station S02 metrics: {'within': {'rmse': 1.1593711404119988, 'mae': 0.8063171241051879, 'r2': 0.9865079035906327}, 'stacked': {'rmse': 1.1555445021477029, 'mae': 0.8026663857827719, 'r2': 0.9865968210498269}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S02.png\n",
      "INFO:panel_forecast:Station S03 metrics: {'within': {'rmse': 1.1585547724443055, 'mae': 0.8400301205475635, 'r2': 0.9821492734175205}, 'stacked': {'rmse': 1.1514496454875902, 'mae': 0.8321243210824041, 'r2': 0.9823675501328685}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S03.png\n",
      "INFO:panel_forecast:Station S04 metrics: {'within': {'rmse': 1.2238521395263817, 'mae': 0.8154777802702428, 'r2': 0.9875467698614819}, 'stacked': {'rmse': 1.2301340245500263, 'mae': 0.8163527507059423, 'r2': 0.9874185999146092}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S04.png\n",
      "INFO:panel_forecast:Station S05 metrics: {'within': {'rmse': 1.1670303513094515, 'mae': 0.819922964788631, 'r2': 0.9882396001255531}, 'stacked': {'rmse': 1.1608234149982564, 'mae': 0.8151918569305264, 'r2': 0.9883643645509321}}\n",
      "INFO:panel_forecast:Saved plot demo_output/obs_pred_S05.png\n",
      "INFO:panel_forecast:Demo complete with per-station metrics and plots.\n"
     ]
    }
   ],
   "source": [
    "# Per-station metrics and plots\n",
    "stations = Xs.index.get_level_values(0).unique()\n",
    "all_metrics = {}\n",
    "for s in stations:\n",
    "    mask = Xs.index.get_level_values(0) == s\n",
    "    metrics_within = evaluate_predictions(y.loc[mask], y_pred_within.loc[mask])\n",
    "    # metrics_panel = evaluate_predictions(y.loc[mask], panel_pred.loc[mask])\n",
    "    metrics_stacked = evaluate_predictions(y.loc[mask], y_meta.loc[mask])\n",
    "    all_metrics[s] = {\n",
    "        'within': metrics_within,\n",
    "        # 'panel': metrics_panel,\n",
    "        'stacked': metrics_stacked\n",
    "    }\n",
    "    logger.info(f\"Station {s} metrics: {all_metrics[s]}\")\n",
    "    # Plot stacked predictions\n",
    "    plot_obs_vs_pred(y.loc[mask], y_meta.loc[mask], station=str(s), out_path=cfg['out_dir'])\n",
    "\n",
    "logger.info(\"Demo complete with per-station metrics and plots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a25bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False], shape=(4386,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'S00'\n",
    "idx = station_ids == s\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7267d3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('station_id', 'date')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fitted_values",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c4ebac1b-0c84-4d79-81c3-7f528ee342ad",
       "rows": [
        [
         "('S00', Timestamp('2019-01-01 00:00:00'))",
         "6.2937102667971825"
        ],
        [
         "('S00', Timestamp('2019-01-02 00:00:00'))",
         "4.436503239741294"
        ],
        [
         "('S00', Timestamp('2019-01-03 00:00:00'))",
         "3.6936655190870127"
        ],
        [
         "('S00', Timestamp('2019-01-04 00:00:00'))",
         "-0.5390882388172987"
        ],
        [
         "('S00', Timestamp('2019-01-05 00:00:00'))",
         "-1.1459888075962896"
        ],
        [
         "('S00', Timestamp('2019-01-06 00:00:00'))",
         "8.89760235191043"
        ],
        [
         "('S00', Timestamp('2019-01-07 00:00:00'))",
         "0.6101897465491348"
        ],
        [
         "('S00', Timestamp('2019-01-08 00:00:00'))",
         "3.422371774617959"
        ],
        [
         "('S00', Timestamp('2019-01-09 00:00:00'))",
         "6.0442926458514945"
        ],
        [
         "('S00', Timestamp('2019-01-10 00:00:00'))",
         "-0.9504064571005105"
        ],
        [
         "('S00', Timestamp('2019-01-11 00:00:00'))",
         "7.862308280040713"
        ],
        [
         "('S00', Timestamp('2019-01-12 00:00:00'))",
         "3.7823765651594985"
        ],
        [
         "('S00', Timestamp('2019-01-13 00:00:00'))",
         "-1.6800796795348019"
        ],
        [
         "('S00', Timestamp('2019-01-14 00:00:00'))",
         "2.8563757317117853"
        ],
        [
         "('S00', Timestamp('2019-01-15 00:00:00'))",
         "5.510272975398172"
        ],
        [
         "('S00', Timestamp('2019-01-16 00:00:00'))",
         "2.6365340764382617"
        ],
        [
         "('S00', Timestamp('2019-01-17 00:00:00'))",
         "-1.752266257888005"
        ],
        [
         "('S00', Timestamp('2019-01-18 00:00:00'))",
         "7.488551178595296"
        ],
        [
         "('S00', Timestamp('2019-01-19 00:00:00'))",
         "2.216215342349697"
        ],
        [
         "('S00', Timestamp('2019-01-20 00:00:00'))",
         "2.491133753782415"
        ],
        [
         "('S00', Timestamp('2019-01-21 00:00:00'))",
         "4.096179085548489"
        ],
        [
         "('S00', Timestamp('2019-01-22 00:00:00'))",
         "0.04457489710025539"
        ],
        [
         "('S00', Timestamp('2019-01-23 00:00:00'))",
         "-0.7877993721791795"
        ],
        [
         "('S00', Timestamp('2019-01-24 00:00:00'))",
         "1.6515081397091722"
        ],
        [
         "('S00', Timestamp('2019-01-25 00:00:00'))",
         "0.545530478922066"
        ],
        [
         "('S00', Timestamp('2019-01-26 00:00:00'))",
         "1.0989741671798128"
        ],
        [
         "('S00', Timestamp('2019-01-27 00:00:00'))",
         "3.3165478904024916"
        ],
        [
         "('S00', Timestamp('2019-01-28 00:00:00'))",
         "-2.3169071580334193"
        ],
        [
         "('S00', Timestamp('2019-01-29 00:00:00'))",
         "-2.331155911416745"
        ],
        [
         "('S00', Timestamp('2019-01-30 00:00:00'))",
         "-0.06744936606775706"
        ],
        [
         "('S00', Timestamp('2019-01-31 00:00:00'))",
         "1.1942173890311811"
        ],
        [
         "('S00', Timestamp('2019-02-01 00:00:00'))",
         "-3.79513329852941"
        ],
        [
         "('S00', Timestamp('2019-02-02 00:00:00'))",
         "0.3867215283729974"
        ],
        [
         "('S00', Timestamp('2019-02-03 00:00:00'))",
         "-2.913038728939033"
        ],
        [
         "('S00', Timestamp('2019-02-04 00:00:00'))",
         "-4.255387455669425"
        ],
        [
         "('S00', Timestamp('2019-02-05 00:00:00'))",
         "1.7279260893366128"
        ],
        [
         "('S00', Timestamp('2019-02-06 00:00:00'))",
         "-0.1659532758457434"
        ],
        [
         "('S00', Timestamp('2019-02-07 00:00:00'))",
         "2.745694229717742"
        ],
        [
         "('S00', Timestamp('2019-02-08 00:00:00'))",
         "-0.9460187470291924"
        ],
        [
         "('S00', Timestamp('2019-02-09 00:00:00'))",
         "-0.5930737777204622"
        ],
        [
         "('S00', Timestamp('2019-02-10 00:00:00'))",
         "-3.090248443643082"
        ],
        [
         "('S00', Timestamp('2019-02-11 00:00:00'))",
         "-1.9239591358085728"
        ],
        [
         "('S00', Timestamp('2019-02-12 00:00:00'))",
         "-1.9564927862455341"
        ],
        [
         "('S00', Timestamp('2019-02-13 00:00:00'))",
         "-6.70578718403673"
        ],
        [
         "('S00', Timestamp('2019-02-14 00:00:00'))",
         "-0.7467593115366455"
        ],
        [
         "('S00', Timestamp('2019-02-15 00:00:00'))",
         "-2.545563900012734"
        ],
        [
         "('S00', Timestamp('2019-02-16 00:00:00'))",
         "-3.810164018712385"
        ],
        [
         "('S00', Timestamp('2019-02-17 00:00:00'))",
         "-6.059342094511089"
        ],
        [
         "('S00', Timestamp('2019-02-18 00:00:00'))",
         "-5.9651618405512625"
        ],
        [
         "('S00', Timestamp('2019-02-19 00:00:00'))",
         "-0.869655916462783"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2196
       }
      },
      "text/plain": [
       "station_id  date      \n",
       "S00         2019-01-01    6.293710\n",
       "            2019-01-02    4.436503\n",
       "            2019-01-03    3.693666\n",
       "            2019-01-04   -0.539088\n",
       "            2019-01-05   -1.145989\n",
       "                            ...   \n",
       "S05         2019-12-28   -6.016113\n",
       "            2019-12-29   -6.501794\n",
       "            2019-12-30   -4.303673\n",
       "            2019-12-31   -4.262841\n",
       "            2020-01-01   -6.537705\n",
       "Name: fitted_values, Length: 2196, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "096b13cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 4386 instead of 2196",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m metrics_within_s = evaluate_predictions(y[idx], y_pred_within[idx])\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Panel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m metrics_panel_s = evaluate_predictions(y[idx], \u001b[43mpanel_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Stacked\u001b[39;00m\n\u001b[32m     12\u001b[39m metrics_meta_s = evaluate_predictions(y[idx], y_meta[idx])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1158\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_slice(key)\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1158\u001b[39m     key = \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1159\u001b[39m     key = np.asarray(key, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m   1160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_rows_with_mask(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2716\u001b[39m, in \u001b[36mcheck_bool_indexer\u001b[39m\u001b[34m(index, key)\u001b[39m\n\u001b[32m   2712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[32m   2713\u001b[39m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[32m   2714\u001b[39m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[32m   2715\u001b[39m     result = pd_array(result, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psh2610\\w\\GitHub\\ShiraziAlianPooya\\panel-data-eto\\.venv\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:539\u001b[39m, in \u001b[36mcheck_array_indexer\u001b[39m\u001b[34m(array, indexer)\u001b[39m\n\u001b[32m    537\u001b[39m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) != \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    540\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBoolean index has wrong length: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m         )\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: Boolean index has wrong length: 4386 instead of 2196"
     ]
    }
   ],
   "source": [
    "# station ids\n",
    "station_ids = Xs.index.get_level_values(0)\n",
    "\n",
    "#    \n",
    "for s in station_ids.unique():\n",
    "    idx = station_ids == s\n",
    "    # Within-station\n",
    "    metrics_within_s = evaluate_predictions(y[idx], y_pred_within[idx])\n",
    "    # Panel\n",
    "    metrics_panel_s = evaluate_predictions(y[idx], panel_pred[idx])\n",
    "    # Stacked\n",
    "    metrics_meta_s = evaluate_predictions(y[idx], y_meta[idx])\n",
    "    print(f\"Station {s}:\")\n",
    "    print(f\"  Within: {metrics_within_s}\")\n",
    "    print(f\"  Panel:  {metrics_panel_s}\")\n",
    "    print(f\"  Stacked: {metrics_meta_s}\")\n",
    "\n",
    "    #  \n",
    "    plot_obs_vs_pred(y[idx], y_pred_within[idx], station=str(s), out_path=\"plots/within\")\n",
    "    plot_obs_vs_pred(y[idx], panel_pred[idx], station=str(s), out_path=\"plots/panel\")\n",
    "    plot_obs_vs_pred(y[idx], y_meta[idx], station=str(s), out_path=\"plots/stacked\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panel-data-eto (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
